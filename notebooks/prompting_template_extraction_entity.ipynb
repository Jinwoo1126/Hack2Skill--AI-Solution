{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ENZ9UpglEIjh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompt_values import ImageURL\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, HttpUrl, validator\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/chat-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 Chat (Legacy)',\n",
      "      description='A legacy text-only model optimized for chat conversations',\n",
      "      input_token_limit=4096,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
      "      temperature=0.25,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/text-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 (Legacy)',\n",
      "      description='A legacy model that understands text and generates text as an output',\n",
      "      input_token_limit=8196,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
      "      temperature=0.7,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/embedding-gecko-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding Gecko',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=1024,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-1.0-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
      "                   'model that supports tuning.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-1.0-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Latest',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
      "                   'model.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-1.0-pro-vision-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-1.5-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro',\n",
      "      description='Mid-size multimodal model that supports up to 1 million tokens',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-pro-vision',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/embedding-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding 001',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/text-embedding-004',\n",
      "      base_model_id='',\n",
      "      version='004',\n",
      "      display_name='Text Embedding 004',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/aqa',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Model that performs Attributed Question Answering.',\n",
      "      description=('Model trained to return answers to questions that are grounded in provided '\n",
      "                   'sources, along with estimating answerable probability.'),\n",
      "      input_token_limit=7168,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateAnswer'],\n",
      "      temperature=0.2,\n",
      "      top_p=1.0,\n",
      "      top_k=40)\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GxCivcn17hqi"
   },
   "outputs": [],
   "source": [
    "class TagsForAspects(BaseModel):\n",
    "    \n",
    "    room_sentiment: list[str] = Field(..., description = \"The sentiments of the room the user wants\");\n",
    "    \n",
    "    room_color: list[str] = Field(..., description = \"The overall atmospheres that depicted to a color\");\n",
    "    \n",
    "    room_size: list[int] = Field(..., description = \"room size expressed in square meters\", enum = list(range(1, 100)));\n",
    "    \n",
    "    housing_type: list[str] = Field(..., description = \"The type of housing\",\n",
    "                              enum = ['studio', 'apartment', 'house']);\n",
    "    \n",
    "    room_type: list[str] = Field(..., description = \"The type of room\",\n",
    "                           enum = ['living room', 'kitchen', 'home office', 'bedroom', 'bathroom', 'dining room', 'office', 'garage', 'basement', 'attic', 'laundry room', 'pantry', 'family room', 'foyer']);\n",
    "\n",
    "class SentenceToAspect:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.GOOGLE_API_KEY = GOOGLE_API_KEY\n",
    "        self.llm = ChatGoogleGenerativeAI(model = 'gemini-pro', google_api_key = self.GOOGLE_API_KEY,\n",
    "                                         temperature = 0)\n",
    "\n",
    "        self.parser = PydanticOutputParser(pydantic_object = TagsForAspects)\n",
    "        self.prompt = PromptTemplate(\n",
    "            template = \"\"\"Answer the user query. \\n {format_instructions}\\n{query}\\n\n",
    "            \n",
    "            1. You must extract the formatted aspect from each word or keyword within query sentence, rather than the sentence as a whole.\n",
    "            2. Please concentrate metric information if it is considerated in the original human message.\n",
    "            3. If you don't think that there is no appropriate words for those aspects, you must return the word 'none' to the aspect\n",
    "            \"\"\",\n",
    "            input_variables = [\"query\"],\n",
    "            partial_variables = {\"format_instructions\" : self.parser.get_format_instructions()}\n",
    "        )\n",
    "\n",
    "    def query(self, query_sentence: str):\n",
    "\n",
    "        chain = self.prompt | self.llm | self.parser\n",
    "        return chain.invoke({\"query\" : query_sentence})\n",
    "\n",
    "class ImageToAspect(SentenceToAspect):\n",
    "\n",
    "    def __init__(self):\n",
    "        SentenceToAspect.__init__(self)\n",
    "        \n",
    "        self.GOOGLE_API_KEY = GOOGLE_API_KEY\n",
    "        self.lmm = ChatGoogleGenerativeAI(model = 'gemini-pro-vision', google_api_key = self.GOOGLE_API_KEY)\n",
    "\n",
    "    def query_img(self, url:str = None):\n",
    "\n",
    "        self.message = HumanMessage(\n",
    "            content = [\n",
    "                {'type': 'text',\n",
    "                 'text': \"\"\"Here is how you must depict an image of a room in English, making sure to include the following elements:\n",
    "                 \n",
    "                 1. Include at least one word that conveys the sentiment of the room. If there are multiple sentiments that describe the image, feel free to include all that apply.\n",
    "                 2. Describe the overall color scheme of the room using at least two color terms.\n",
    "                 3. Estimate the size of the room in square meters and provide the figure numerically.\n",
    "                 4. Determine whether the room belongs to an apartment, studio, or house, and specify which one.\n",
    "                 5. Guess which part of the house the room might be, such as the living room, bedroom, etc.\"\"\"}\n",
    "                ,\n",
    "                {'type' : 'image_url',\n",
    "                 'image_url' : url}\n",
    "            ]           \n",
    "        )\n",
    "        \n",
    "        self.return_sentence_img = self.lmm.invoke([self.message])\n",
    "        return self.query(query_sentence = self.return_sentence_img.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7N--m7deM8Cz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ita = ImageToAspect()\n",
    "output_ita = ita.query_img(url = 'https://image.ohou.se/i/bucketplace-v2-development/uploads/cards/snapshots/169087905318351049.jpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TagsForAspects(room_sentiment=['warm', 'inviting'], room_color=['white', 'light gray', 'brown'], room_size=[25], housing_type=['apartment'], room_type=['living room'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
